{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/Users/parkkyuseon/Downloads/chromedriver')\n",
    "driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"3d2c43c62a68f699d5d6dd871fa9e4bd\")>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.get('https://www.baseball-reference.com/register/league.cgi?id=30c06d74')\n",
    "driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_team_off = [['Yr', 'Team', 'R/G', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', \n",
    "                 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'TB',\n",
    "                 'GDP', 'HBP', 'SH', 'SF', 'IBB']]\n",
    "col_team_def = [['Yr', 'Team', 'RA/G', 'W', 'L', 'WP', 'ERA', 'RA9', 'G', 'GS', 'GF', 'CG', 'SHO', 'SV',\n",
    "                 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF',\n",
    "                 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W']]\n",
    "col_team_info = [['yr', 'Team', 'League', 'W', 'L', 'Ties', 'WPCT']]\n",
    "\n",
    "team_off = pd.DataFrame(columns = col_team_off)\n",
    "team_def = pd.DataFrame(columns = col_team_def)\n",
    "team_info = pd.DataFrame(columns = col_team_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NPB Pacific League\n",
    "driver.get('https://www.baseball-reference.com/register/league.cgi?id=30c06d74')\n",
    "driver\n",
    "\n",
    "year = range(2020, 1949, -1)\n",
    "for yr in year:\n",
    "    driver.implicitly_wait(15)\n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_batting\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_off.columns\n",
    "        team_off = pd.concat([team_off, data])\n",
    "        \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_pitching\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "    \n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_def.columns\n",
    "        team_def = pd.concat([team_def, data])\n",
    "    \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"regular_season\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[0:4]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name, 'NPB'] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_info.columns\n",
    "        team_info = pd.concat([team_info, data])\n",
    "        \n",
    "    driver.find_element_by_xpath('//*[@id=\"meta\"]/div/div/a').send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NPB Central League\n",
    "driver.get('https://www.baseball-reference.com/register/league.cgi?id=4b244907')\n",
    "driver\n",
    "\n",
    "year = range(2020, 1949, -1)\n",
    "for yr in year:\n",
    "    driver.implicitly_wait(15)\n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_batting\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_off.columns\n",
    "        team_off = pd.concat([team_off, data])\n",
    "        \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_pitching\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "    \n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_def.columns\n",
    "        team_def = pd.concat([team_def, data])\n",
    "    \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"regular_season\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[0:4]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name, 'NPB'] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_info.columns\n",
    "        team_info = pd.concat([team_info, data])\n",
    "        \n",
    "    driver.find_element_by_xpath('//*[@id=\"meta\"]/div/div/a').send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NPB(1949~1938)\n",
    "driver.get('https://www.baseball-reference.com/register/league.cgi?id=11f49723')\n",
    "driver\n",
    "\n",
    "year = range(1949, 1945, -1)\n",
    "for yr in year:\n",
    "    driver.implicitly_wait(15)\n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_batting\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_off.columns\n",
    "        team_off = pd.concat([team_off, data])\n",
    "        \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_pitching\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "    \n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_def.columns\n",
    "        team_def = pd.concat([team_def, data])\n",
    "    \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"regular_season\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[0:4]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name, 'NPB'] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_info.columns\n",
    "        team_info = pd.concat([team_info, data])\n",
    "        \n",
    "    driver.find_element_by_xpath('//*[@id=\"meta\"]/div/div/a').send_keys(Keys.ENTER)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"meta\"]/div/div/a').send_keys(Keys.ENTER)\n",
    "year = range(1944, 1938, -1)\n",
    "for yr in year:\n",
    "    driver.implicitly_wait(15)\n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_batting\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_off.columns\n",
    "        team_off = pd.concat([team_off, data])\n",
    "        \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_pitching\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "    \n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_def.columns\n",
    "        team_def = pd.concat([team_def, data])\n",
    "    \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"regular_season\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[0:4]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name, 'NPB'] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_info.columns\n",
    "        team_info = pd.concat([team_info, data])\n",
    "        \n",
    "    driver.find_element_by_xpath('//*[@id=\"meta\"]/div/div/a').send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NPB(1938~1936 / FALL)\n",
    "driver.get('https://www.baseball-reference.com/register/league.cgi?id=c5c0c9b0')\n",
    "driver\n",
    "\n",
    "year = range(1938, 1935, -1)\n",
    "for yr in year:\n",
    "    driver.implicitly_wait(15)\n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_batting\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_off.columns\n",
    "        team_off = pd.concat([team_off, data])\n",
    "        \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_pitching\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "    \n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_def.columns\n",
    "        team_def = pd.concat([team_def, data])\n",
    "    \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"regular_season\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[0:4]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name, 'NPB'] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_info.columns\n",
    "        team_info = pd.concat([team_info, data])\n",
    "        \n",
    "    driver.find_element_by_xpath('//*[@id=\"meta\"]/div/div/a').send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NPB(1938~1937 / SPRING)\n",
    "driver.get('https://www.baseball-reference.com/register/league.cgi?id=8571b28f')\n",
    "driver\n",
    "\n",
    "year = range(1938, 1936, -1)\n",
    "for yr in year:\n",
    "    driver.implicitly_wait(15)\n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_batting\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_off.columns\n",
    "        team_off = pd.concat([team_off, data])\n",
    "        \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"league_pitching\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "    \n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[2::]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_def.columns\n",
    "        team_def = pd.concat([team_def, data])\n",
    "    \n",
    "    table = driver.find_element_by_xpath('//*[@id=\"regular_season\"]/tbody').get_attribute(\"innerHTML\") \n",
    "    soup = BeautifulSoup(table, 'html.parser') \n",
    "\n",
    "    for i in range(0,len(soup.findAll('tr'))):\n",
    "        team_name = soup.findAll('tr')[i].get_text()[0:8]\n",
    "        data = soup.findAll('tr')[i]\n",
    "        data = data.findAll('td')[0:4]\n",
    "        for j in range(0, len(data)):\n",
    "            data[j] = data[j].get_text()\n",
    "        data = [yr, team_name, 'NPB'] + data\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = team_info.columns\n",
    "        team_info = pd.concat([team_info, data])\n",
    "        \n",
    "    driver.find_element_by_xpath('//*[@id=\"meta\"]/div/div/a').send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_off.to_csv('team_off.csv', index=True, header=True)\n",
    "team_def.to_csv('team_def.csv', index=True, header=True)\n",
    "team_info.to_csv('team_info.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
